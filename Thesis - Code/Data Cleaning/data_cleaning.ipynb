{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from w3lib.html import remove_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\gilnr\\\\OneDrive - NOVASBE\\\\Work Project\\\\Thesis - Code\\\\Data Cleaning'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "while not os.getcwd().endswith(\"Data Cleaning\"):\n",
    "    os.chdir(\"..\")\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('c:/Users/gilnr/OneDrive - NOVASBE/Work Project/Thesis - Code/Data')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path, PureWindowsPath\n",
    "\n",
    "main_folder = PureWindowsPath(\"c:\\\\Users\\\\gilnr\\\\OneDrive - NOVASBE\\\\Work Project\\\\Thesis - Code\")\n",
    "MAIN_FOLDER = Path(main_folder)\n",
    "DATA_FOLDER = MAIN_FOLDER / \"Data\"\n",
    "DATA_FOLDER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load all datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "bons_empregos = pd.read_json(DATA_FOLDER / 'bons_empregos_jobs.json')\n",
    "career_jet = pd.read_json(DATA_FOLDER / 'career_jet_api.json')\n",
    "carga_de_trabalhos = pd.read_json(DATA_FOLDER / 'CargaDeTrabalhos.json', lines=True)\n",
    "emprego_xl = pd.read_json(DATA_FOLDER / 'emprego_xl_jobs.json')\n",
    "emprego_org = pd.read_json(DATA_FOLDER / 'empregoOrg_jobs.json')\n",
    "itjobs = pd.read_json(DATA_FOLDER / 'itjobs_api.json')\n",
    "jooble = pd.read_json(DATA_FOLDER / 'jooble_api.json')\n",
    "landing_jobs = pd.read_json(DATA_FOLDER / 'landingjobs_api.json')\n",
    "net_empregos = pd.read_json(DATA_FOLDER / 'net_empregos.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "- For each website there are specific categories that we need to attend. Some require filtering for job location, others cleaning the job description, and the post date.\n",
    "\n",
    "## Drop Job Vacancies\n",
    "What makes a unique job vacancy?\n",
    "- For our analysis it will be: [job_title, job_description, company, job_location]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def description():\n",
    "    \"\"\"Clean job description of:\n",
    "    Weird characters (\\n, \\r, \\r\\n,-, etc...)\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_df(dataframe):\n",
    "   return dataframe.copy()\n",
    "\n",
    "def replacenan(dataframe):\n",
    "    dataframe.replace('nan', np.nan, inplace=True)\n",
    "    return dataframe\n",
    "    \n",
    "def dropNullJobs(dataframe):\n",
    "    \"\"\"\n",
    "    Drop null values that make an online job vacancy unusable for analysis.\n",
    "    The subset to drop is: ['post_date', 'job_title', 'job_description']\n",
    "    \"\"\"\n",
    "    dataframe.dropna(subset=['post_date', 'job_title', 'job_description'], inplace=True)\n",
    "    return dataframe\n",
    "\n",
    "# Convert Scrape date to datetime\n",
    "def toDatetime(dataFrame, columns_list):\n",
    "    for i in columns_list:\n",
    "        dataFrame[i] = pd.to_datetime(dataFrame[i])\n",
    "    return dataFrame\n",
    "\n",
    "# remove duplicates\n",
    "def removeDupes(dataframe, subset=['job_title', 'job_description', 'company', 'job_location']):\n",
    "    dataframe.sort_values(by='post_date').drop_duplicates(subset=subset, keep='last', inplace=True)\n",
    "    return dataframe\n",
    "\n",
    "# convert portuguese months to numbers\n",
    "def longToShortDate(x, sep):\n",
    "    months = ['janeiro', 'fevereiro','março', 'abril', 'maio', 'junho', 'julho', 'agosto', 'setembro', 'outubro', 'novembro', 'dezembro']\n",
    "    months_dic = {value:idx+1 for idx, value in enumerate(months)}\n",
    "    date = [i.strip() for i in x.split(sep)]\n",
    "    return f'{date[0]}/{months_dic[date[1]]}/{date[2]}'\n",
    "\n",
    "# convert to datetime object\n",
    "def convertToDatetime(dataframe, function, sep=' '):\n",
    "    # Remove comma from date\n",
    "    dataframe['post_date'] = dataframe['post_date'].apply(lambda x: str(x).lower().replace(',',''))\n",
    "    dataframe['post_date'] = dataframe['post_date'].apply(lambda x: dt.datetime.strptime(function(x, sep), \"%d/%m/%Y\"))\n",
    "    return dataframe\n",
    "\n",
    "def listToRows(dataframe, column):\n",
    "    return dataframe.explode(column)\n",
    "\n",
    "def removeTags(dataframe, column_list):\n",
    "    for i in column_list:\n",
    "        dataframe[i] = dataframe[i].apply(remove_tags)\n",
    "    return dataframe\n",
    "\n",
    "def postDatePreprocess(dataframe, sep=\" \"):\n",
    "    dataframe['post_date'] = dataframe['post_date'].apply(lambda x: x.split(sep)[0]) \n",
    "    return dataframe\n",
    "\n",
    "# Description\n",
    "def clean_text(text):\n",
    "    to_replace = ['\\r', '\\n', '•']\n",
    "    replace = ['', '', '\\n']\n",
    "\n",
    "    for idx, val in enumerate(to_replace):\n",
    "        text = text.replace(val, replace[idx])\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "def cleanDescription(dataframe, column_list):\n",
    "    for i in column_list:\n",
    "        dataframe[i] = dataframe[i].apply(lambda x: clean_text(x))\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bons Empregos\n",
    "- Specific functions:\n",
    "    - `getPortugalLocation`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPortugalLocation(dataframe):\n",
    "    # Get only job offers in Portugal\n",
    "    dataframe = dataframe.loc[dataframe['job_location'] != 'Estrangeiro'].copy()\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous shape: (2576, 8)\n",
      "Current shape:(2357, 8)\n"
     ]
    }
   ],
   "source": [
    "bons_empregos_clean = (bons_empregos.\n",
    "                    pipe(copy_df).\n",
    "                    pipe(replacenan).\n",
    "                    pipe(dropNullJobs).\n",
    "                    pipe(toDatetime, ['scrape_date']).\n",
    "                    pipe(getPortugalLocation).\n",
    "                    pipe(convertToDatetime, longToShortDate).\n",
    "                    pipe(removeDupes)\n",
    ")\n",
    "\n",
    "print(f'Previous shape: {bons_empregos.shape}\\nCurrent shape:{bons_empregos_clean.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Career Jet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert job location to list\n",
    "career_jet['job_location'] = career_jet['job_location'].apply(lambda x: x.split(','))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous shape: (6534, 9)\n",
      "Current shape:(10613, 9)\n"
     ]
    }
   ],
   "source": [
    "career_jet_clean = (career_jet.\n",
    "                    pipe(copy_df).\n",
    "                    pipe(replacenan).\n",
    "                    pipe(dropNullJobs).\n",
    "                    pipe(toDatetime, ['scrape_date', 'post_date']).\n",
    "                    pipe(listToRows, 'job_location').\n",
    "                    pipe(removeDupes)\n",
    ")\n",
    "print(f'Previous shape: {career_jet.shape}\\nCurrent shape:{career_jet_clean.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert career_jet_clean.post_date.dtypes == career_jet_clean.scrape_date.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de Trabalhos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous shape: (80, 7)\n",
      "Current shape:(80, 7)\n"
     ]
    }
   ],
   "source": [
    "carga_de_trabalhos_clean = (carga_de_trabalhos.\n",
    "                    pipe(copy_df).\n",
    "                    pipe(replacenan).\n",
    "                    pipe(dropNullJobs).\n",
    "                    pipe(toDatetime, ['scrape_date']).\n",
    "                    pipe(convertToDatetime, longToShortDate, '/').\n",
    "                    pipe(removeDupes)\n",
    ")\n",
    "\n",
    "print(f'Previous shape: {carga_de_trabalhos.shape}\\nCurrent shape:{carga_de_trabalhos_clean.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emprego XL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emprego_xl_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emprego.Org `SCRAPE AGAIN WITH SCRAPY FOR THE CORRECT FIELDS`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emprego_org_clean = (emprego_org.\n",
    "#                     pipe(copy_df).\n",
    "#                     pipe(replacenan).\n",
    "#                     pipe(dropNullJobs).\n",
    "#                     pipe(postDatePreprocess, '/').\n",
    "#                     pipe(toDatetime, ['scrape_date', 'post_date']).\n",
    "#                     pipe(removeDupes)\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ITJOBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous shape: (3890, 9)\n",
      "Current shape:(5076, 9)\n"
     ]
    }
   ],
   "source": [
    "itjobs_clean = (itjobs.\n",
    "                    pipe(copy_df).\n",
    "                    pipe(listToRows, 'job_location').\n",
    "                    pipe(replacenan).\n",
    "                    pipe(dropNullJobs).\n",
    "                    pipe(toDatetime, ['scrape_date', 'post_date']).\n",
    "                    pipe(removeDupes)\n",
    ")\n",
    "\n",
    "print(f'Previous shape: {itjobs.shape}\\nCurrent shape:{itjobs_clean.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jooble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous shape: (1093, 9)\n",
      "Current shape:(1093, 9)\n"
     ]
    }
   ],
   "source": [
    "jooble_clean = (jooble.\n",
    "                    pipe(copy_df).\n",
    "                    pipe(replacenan).\n",
    "                    pipe(dropNullJobs).\n",
    "                    pipe(toDatetime, ['scrape_date', 'post_date']).\n",
    "                    pipe(removeTags, ['job_title']).\n",
    "                    pipe(removeDupes)\n",
    ")\n",
    "\n",
    "print(f'Previous shape: {jooble.shape}\\nCurrent shape:{jooble_clean.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Landing Jobs IT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous shape: (717, 9)\n",
      "Current shape:(717, 9)\n"
     ]
    }
   ],
   "source": [
    "landing_jobs_clean = (landing_jobs.\n",
    "                    pipe(copy_df).\n",
    "                    pipe(replacenan).\n",
    "                    pipe(dropNullJobs).\n",
    "                    pipe(postDatePreprocess, 'T').\n",
    "                    pipe(toDatetime, ['scrape_date', 'post_date']).\n",
    "                    pipe(removeTags, 'job_title').\n",
    "                    pipe(removeDupes)\n",
    ")\n",
    "\n",
    "print(f'Previous shape: {landing_jobs.shape}\\nCurrent shape:{landing_jobs_clean.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Net Empregos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous shape: (54800, 8)\n",
      "Current shape:(54791, 8)\n"
     ]
    }
   ],
   "source": [
    "net_empregos_clean = (net_empregos.\n",
    "                    pipe(copy_df).\n",
    "                    pipe(replacenan).\n",
    "                    pipe(dropNullJobs).\n",
    "                    pipe(cleanDescription, ['job_title']).\n",
    "                    pipe(toDatetime, ['scrape_date', 'post_date']).\n",
    "                    pipe(removeDupes)\n",
    ")\n",
    "\n",
    "print(f'Previous shape: {net_empregos.shape}\\nCurrent shape:{net_empregos_clean.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Website Column to all dataframes before concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_dfs = [bons_empregos_clean, career_jet_clean, carga_de_trabalhos_clean, #emprego_xl_clean, emprego_org_clean, \n",
    "            itjobs_clean, jooble_clean, landing_jobs_clean, net_empregos_clean]\n",
    "websites = ['Bons empregos', 'Career Jet', 'Carga de Trabalhos',#'Emprego XL', 'Emprego.org' \n",
    "            'ITjobs','Jooble','Landing Jobs','Net-empregos']\n",
    "\n",
    "# Add column with website name\n",
    "for idx, value in enumerate(jobs_dfs):\n",
    "    value['website'] = websites[idx]   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concat All dataframes into one for data Deduplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "neworder = ['job_title','job_description','company','job_location','job_category','salary', 'post_date', 'scrape_date','job_href', 'website']\n",
    "\n",
    "df = pd.concat([i.reindex(columns=neworder) for i in jobs_dfs])\n",
    "\n",
    "# Validate that the concatenation is happening properly\n",
    "assert len(df) == sum(len(i) for i in jobs_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 74727 entries, 10 to 54799\n",
      "Data columns (total 10 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   job_title        74727 non-null  object        \n",
      " 1   job_description  74727 non-null  object        \n",
      " 2   company          73987 non-null  object        \n",
      " 3   job_location     74727 non-null  object        \n",
      " 4   job_category     74647 non-null  object        \n",
      " 5   salary           12483 non-null  object        \n",
      " 6   post_date        74727 non-null  datetime64[ns]\n",
      " 7   scrape_date      74727 non-null  datetime64[ns]\n",
      " 8   job_href         67841 non-null  object        \n",
      " 9   website          74727 non-null  object        \n",
      "dtypes: datetime64[ns](2), object(8)\n",
      "memory usage: 6.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanCompany(dataframe):\n",
    "    def capitalize(x):\n",
    "        try:\n",
    "            return x.capitalize()\n",
    "        except AttributeError:\n",
    "            return ''\n",
    "    dataframe['company'] = dataframe['company'].apply(lambda x: capitalize(x))\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous shape: (74727, 10)\n",
      "Current shape:(74727, 10)\n"
     ]
    }
   ],
   "source": [
    "df_clean = (df.\n",
    "            pipe(copy_df).\n",
    "            pipe(replacenan).\n",
    "            pipe(dropNullJobs).\n",
    "            pipe(cleanCompany).\n",
    "            pipe(cleanDescription, ['job_title', 'job_description']).\n",
    "            pipe(removeDupes, ['job_title', 'company', 'job_location'])\n",
    ")\n",
    "df_clean.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(f'Previous shape: {df.shape}\\nCurrent shape:{df_clean.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 74727 entries, 0 to 74726\n",
      "Data columns (total 10 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   job_title        74727 non-null  object        \n",
      " 1   job_description  74727 non-null  object        \n",
      " 2   company          74727 non-null  object        \n",
      " 3   job_location     74727 non-null  object        \n",
      " 4   job_category     74647 non-null  object        \n",
      " 5   salary           12483 non-null  object        \n",
      " 6   post_date        74727 non-null  datetime64[ns]\n",
      " 7   scrape_date      74727 non-null  datetime64[ns]\n",
      " 8   job_href         67841 non-null  object        \n",
      " 9   website          74727 non-null  object        \n",
      "dtypes: datetime64[ns](2), object(8)\n",
      "memory usage: 5.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is a total of 74727 jobs of which 53415 have unique titles\n"
     ]
    }
   ],
   "source": [
    "print(f'There is a total of {len(df_clean)} jobs of which {df_clean.job_title.nunique()} have unique titles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-157-ea8415b8a3ee>:1: FutureWarning: Treating datetime data as categorical rather than numeric in `.describe` is deprecated and will be removed in a future version of pandas. Specify `datetime_is_numeric=True` to silence this warning and adopt the future behavior now.\n",
      "  df.describe()\n",
      "<ipython-input-157-ea8415b8a3ee>:1: FutureWarning: Treating datetime data as categorical rather than numeric in `.describe` is deprecated and will be removed in a future version of pandas. Specify `datetime_is_numeric=True` to silence this warning and adopt the future behavior now.\n",
      "  df.describe()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_description</th>\n",
       "      <th>company</th>\n",
       "      <th>job_location</th>\n",
       "      <th>job_category</th>\n",
       "      <th>salary</th>\n",
       "      <th>post_date</th>\n",
       "      <th>scrape_date</th>\n",
       "      <th>job_href</th>\n",
       "      <th>website</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>74727</td>\n",
       "      <td>74727</td>\n",
       "      <td>73987</td>\n",
       "      <td>74727</td>\n",
       "      <td>74647</td>\n",
       "      <td>12483</td>\n",
       "      <td>74727</td>\n",
       "      <td>74727</td>\n",
       "      <td>67841</td>\n",
       "      <td>74727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>53434</td>\n",
       "      <td>53279</td>\n",
       "      <td>12930</td>\n",
       "      <td>538</td>\n",
       "      <td>68</td>\n",
       "      <td>143</td>\n",
       "      <td>4154</td>\n",
       "      <td>3</td>\n",
       "      <td>58281</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Ajudante de Cozinha</td>\n",
       "      <td>\\r\\n</td>\n",
       "      <td></td>\n",
       "      <td>Lisboa</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2021-10-22 00:00:00</td>\n",
       "      <td>2021-05-10 00:00:00</td>\n",
       "      <td>http://jobviewtrack.com/pt-pt/job-1d12416e4c16...</td>\n",
       "      <td>Net-empregos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>401</td>\n",
       "      <td>5254</td>\n",
       "      <td>7497</td>\n",
       "      <td>20559</td>\n",
       "      <td>17499</td>\n",
       "      <td>6030</td>\n",
       "      <td>10231</td>\n",
       "      <td>57130</td>\n",
       "      <td>40</td>\n",
       "      <td>54791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-11-16 00:00:00</td>\n",
       "      <td>2021-04-10 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-12-09 00:00:00</td>\n",
       "      <td>2021-10-22 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  job_title           job_description company job_location  \\\n",
       "count                 74727                     74727   73987        74727   \n",
       "unique                53434                     53279   12930          538   \n",
       "top     Ajudante de Cozinha  \\r\\n                                   Lisboa   \n",
       "freq                    401                      5254    7497        20559   \n",
       "first                   NaN                       NaN     NaN          NaN   \n",
       "last                    NaN                       NaN     NaN          NaN   \n",
       "\n",
       "       job_category salary            post_date          scrape_date  \\\n",
       "count         74647  12483                74727                74727   \n",
       "unique           68    143                 4154                    3   \n",
       "top                         2021-10-22 00:00:00  2021-05-10 00:00:00   \n",
       "freq          17499   6030                10231                57130   \n",
       "first           NaN    NaN  2018-11-16 00:00:00  2021-04-10 00:00:00   \n",
       "last            NaN    NaN  2021-12-09 00:00:00  2021-10-22 00:00:00   \n",
       "\n",
       "                                                 job_href       website  \n",
       "count                                               67841         74727  \n",
       "unique                                              58281             7  \n",
       "top     http://jobviewtrack.com/pt-pt/job-1d12416e4c16...  Net-empregos  \n",
       "freq                                                   40         54791  \n",
       "first                                                 NaN           NaN  \n",
       "last                                                  NaN           NaN  "
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.to_json(DATA_FOLDER / 'full_data_clean.json')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e4bff5b682aa07adb254283e21d36547e3dbb28a7d578473d3b997b4eaaa90c6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('mlcourse': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
